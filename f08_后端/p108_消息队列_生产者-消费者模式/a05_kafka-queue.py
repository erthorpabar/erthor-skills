# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”å½“å‰æ–‡ä»¶å¤¹è·¯å¾„åŠ å…¥æœç´¢è·¯å¾„â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”åŠ è½½ç¯å¢ƒå˜é‡â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
from dotenv import load_dotenv
load_dotenv()

from pydantic_settings import BaseSettings
class Settings(BaseSettings):
    # ğŸ“Š Kafkaé…ç½®
    KAFKA_BOOTSTRAP_SERVERS: str = "localhost:9092"
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        extra = "allow"
        case_sensitive = True

settings = Settings()

'''å•ä¾‹'''
from threading import Lock
class SingletonMeta(type):
    _instances = {}
    _lock: Lock = Lock()

    def __call__(cls, *args, **kwargs):
        with cls._lock:
            if cls not in cls._instances:
                instance = super().__call__(*args, **kwargs)
                cls._instances[cls] = instance
        return cls._instances[cls]


import asyncio
import json
from aiokafka import AIOKafkaProducer, AIOKafkaConsumer

class KafkaConsumerGroup(metaclass=SingletonMeta):
    """
    ğŸ“Š Kafka Consumer Group æ¨¡å¼ - ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼
    
    ç‰¹ç‚¹ï¼š
    - åŒä¸€ä¸ªConsumer Groupä¸­ï¼Œä¸€æ¡æ¶ˆæ¯åªè¢«ä¸€ä¸ªæ¶ˆè´¹è€…å¤„ç†
    - åˆ†åŒºæœºåˆ¶ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•
    - æ¶ˆæ¯æŒä¹…åŒ–ï¼Œå¯é‡å¤æ¶ˆè´¹
    - é«˜ååé‡ï¼Œé€‚åˆå¤§æ•°æ®åœºæ™¯
    """
    
    def __init__(self, bootstrap_servers: str):
        self.bootstrap_servers = bootstrap_servers
        self.producer = None
        self.consumers = []
    
    async def create_producer(self):
        """åˆ›å»ºç”Ÿäº§è€…"""
        if not self.producer:
            self.producer = AIOKafkaProducer(
                bootstrap_servers=self.bootstrap_servers,
                value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode('utf-8')
            )
            await self.producer.start()
            print("âœ… Kafka Producer åˆ›å»ºæˆåŠŸ")
    
    async def send_message(self, topic: str, message_data: dict):
        """
        ğŸ“¤ ç”Ÿäº§è€…ï¼šå‘é€æ¶ˆæ¯åˆ°Topic
        
        Args:
            topic: ä¸»é¢˜åç§°
            message_data: æ¶ˆæ¯æ•°æ®ï¼ˆå­—å…¸æ ¼å¼ï¼‰
        """
        await self.create_producer()
        await self.producer.send_and_wait(topic, message_data)
        print(f"âœ… ç”Ÿäº§è€…å‘é€æ¶ˆæ¯åˆ°Topic [{topic}]: {message_data}")
    
    async def consume_messages(self, topic: str, group_id: str, consumer_name: str, callback):
        """
        ğŸ“¥ æ¶ˆè´¹è€…ï¼šæ¶ˆè´¹Topicæ¶ˆæ¯ï¼ˆConsumer Groupæ¨¡å¼ï¼‰
        
        Args:
            topic: ä¸»é¢˜åç§°
            group_id: æ¶ˆè´¹è€…ç»„IDï¼ˆåŒä¸€ç»„å†…çš„æ¶ˆè´¹è€…è´Ÿè½½å‡è¡¡ï¼‰
            consumer_name: æ¶ˆè´¹è€…åç§°
            callback: å¤„ç†æ¶ˆæ¯çš„å›è°ƒå‡½æ•°
        """
        consumer = AIOKafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            group_id=group_id,  # åŒä¸€ä¸ªgroup_idçš„æ¶ˆè´¹è€…ä¼šè´Ÿè½½å‡è¡¡
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            auto_offset_reset='earliest',  # ä»æœ€æ—©çš„æ¶ˆæ¯å¼€å§‹æ¶ˆè´¹
            enable_auto_commit=True
        )
        
        await consumer.start()
        self.consumers.append(consumer)
        print(f"ğŸ‘‚ [{consumer_name}] å¼€å§‹æ¶ˆè´¹Topic: {topic} (Group: {group_id})")
        
        try:
            async for message in consumer:
                message_data = message.value
                print(f"ğŸ“¬ [{consumer_name}] æ”¶åˆ°æ¶ˆæ¯ (åˆ†åŒº{message.partition}): {message_data}")
                await callback(message_data, consumer_name)
        finally:
            await consumer.stop()
    
    async def close(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        if self.producer:
            await self.producer.stop()
        for consumer in self.consumers:
            await consumer.stop()
        print("ğŸ”Œ Kafka è¿æ¥å·²å…³é—­")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”æµ‹è¯•ä»£ç â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
async def test_kafka_consumer_group():
    """æµ‹è¯• Kafka Consumer Group ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼"""
    
    kafka = KafkaConsumerGroup(
        bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS
    )
    
    topic_name = "order_events"
    group_id = "order_processing_group"
    
    # ğŸ¯ åœºæ™¯ï¼šè®¢å•äº‹ä»¶å¤„ç†ï¼ŒåŒä¸€ä¸ªç»„å†…çš„æ¶ˆè´¹è€…è´Ÿè½½å‡è¡¡
    print("\n" + "="*50)
    print("ğŸ“Š Kafka Consumer Group æ¨¡å¼ - ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å¼æµ‹è¯•")
    print("="*50 + "\n")
    
    # æ¶ˆæ¯å¤„ç†å‡½æ•°
    async def process_order_event(message_data: dict, consumer_name: str):
        """å¤„ç†è®¢å•äº‹ä»¶"""
        print(f"ğŸ”¨ [{consumer_name}] å¼€å§‹å¤„ç†è®¢å•...")
        await asyncio.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        print(f"âœ… [{consumer_name}] è®¢å•å¤„ç†å®Œæˆ: {message_data['order_id']}")
    
    # å¯åŠ¨2ä¸ªæ¶ˆè´¹è€…ï¼ˆåŒä¸€ä¸ªConsumer Groupï¼‰
    print("ã€æ¶ˆè´¹è€…ã€‘å¯åŠ¨ä¸­...\n")
    consumer_task1 = asyncio.create_task(
        kafka.consume_messages(topic_name, group_id, "è®¢å•å¤„ç†å™¨-1", process_order_event)
    )
    consumer_task2 = asyncio.create_task(
        kafka.consume_messages(topic_name, group_id, "è®¢å•å¤„ç†å™¨-2", process_order_event)
    )
    
    # ç­‰å¾…æ¶ˆè´¹è€…å‡†å¤‡å¥½
    await asyncio.sleep(2)
    
    # ç”Ÿäº§è€…ï¼šå‘é€5ä¸ªè®¢å•äº‹ä»¶
    print("\nã€ç”Ÿäº§è€…ã€‘å¼€å§‹å‘é€æ¶ˆæ¯...\n")
    for i in range(1, 6):
        await kafka.send_message(topic_name, {
            "order_id": f"ORDER_{i:03d}",
            "user_id": f"USER_{i}",
            "product": f"å•†å“{i}",
            "amount": 100 * i,
            "status": "pending"
        })
        await asyncio.sleep(0.5)
    
    # ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
    await asyncio.sleep(8)
    
    # å–æ¶ˆæ¶ˆè´¹è€…ä»»åŠ¡
    consumer_task1.cancel()
    consumer_task2.cancel()
    
    await asyncio.gather(consumer_task1, consumer_task2, return_exceptions=True)
    await kafka.close()
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(test_kafka_consumer_group())


"""
ğŸ’¡ è¿è¡Œç»“æœè¯´æ˜ï¼š
- åŒä¸€ä¸ªConsumer Groupä¸­ï¼Œæ¯æ¡æ¶ˆæ¯åªè¢«ä¸€ä¸ªæ¶ˆè´¹è€…å¤„ç†
- 5ä¸ªæ¶ˆæ¯ä¼šè¢«2ä¸ªæ¶ˆè´¹è€…è½®æµå¤„ç†ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
- æ”¯æŒåˆ†åŒºï¼Œå¯æ°´å¹³æ‰©å±•
- é€‚åˆï¼šæ—¥å¿—æ”¶é›†ã€äº‹ä»¶å¤„ç†ã€æ•°æ®ç®¡é“ç­‰å¤§æ•°æ®åœºæ™¯

ğŸ“¦ å®‰è£…ä¾èµ–ï¼š
pip install aiokafka

ğŸ³ Docker å¯åŠ¨ Kafkaï¼š
# 1. å¯åŠ¨ Zookeeper
docker run -d --name zookeeper -p 2181:2181 zookeeper:3.7

# 2. å¯åŠ¨ Kafka
docker run -d --name kafka -p 9092:9092 \
  -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
  --link zookeeper \
  confluentinc/cp-kafka:latest
"""