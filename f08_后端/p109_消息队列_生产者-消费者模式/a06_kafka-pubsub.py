# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”å½“å‰æ–‡ä»¶å¤¹è·¯å¾„åŠ å…¥æœç´¢è·¯å¾„â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”åŠ è½½ç¯å¢ƒå˜é‡â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
from dotenv import load_dotenv
load_dotenv()

from pydantic_settings import BaseSettings
class Settings(BaseSettings):
    # ğŸ“Š Kafkaé…ç½®
    KAFKA_BOOTSTRAP_SERVERS: str = "localhost:9092"
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        extra = "allow"
        case_sensitive = True

settings = Settings()

'''å•ä¾‹'''
from threading import Lock
class SingletonMeta(type):
    _instances = {}
    _lock: Lock = Lock()

    def __call__(cls, *args, **kwargs):
        with cls._lock:
            if cls not in cls._instances:
                instance = super().__call__(*args, **kwargs)
                cls._instances[cls] = instance
        return cls._instances[cls]


import asyncio
import json
from aiokafka import AIOKafkaProducer, AIOKafkaConsumer

class KafkaMultipleGroups(metaclass=SingletonMeta):
    """
    ğŸ“Š Kafka å¤šä¸ª Consumer Group æ¨¡å¼ - å‘å¸ƒè®¢é˜…æ¨¡å¼
    
    ç‰¹ç‚¹ï¼š
    - ä¸åŒConsumer Groupï¼Œæ¯ä¸ªç»„éƒ½ä¼šæ”¶åˆ°æ‰€æœ‰æ¶ˆæ¯ï¼ˆå¹¿æ’­ï¼‰
    - æ¶ˆæ¯æŒä¹…åŒ–ï¼Œå¯é‡å¤æ¶ˆè´¹
    - æ”¯æŒæµ·é‡æ•°æ®
    - é€‚åˆéœ€è¦æŒä¹…åŒ–å’Œé«˜ååçš„å¹¿æ’­åœºæ™¯
    """
    
    def __init__(self, bootstrap_servers: str):
        self.bootstrap_servers = bootstrap_servers
        self.producer = None
        self.consumers = []
    
    async def create_producer(self):
        """åˆ›å»ºç”Ÿäº§è€…"""
        if not self.producer:
            self.producer = AIOKafkaProducer(
                bootstrap_servers=self.bootstrap_servers,
                value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode('utf-8')
            )
            await self.producer.start()
            print("âœ… Kafka Producer åˆ›å»ºæˆåŠŸ")
    
    async def publish_event(self, topic: str, event_data: dict):
        """
        ğŸ“¤ å‘å¸ƒè€…ï¼šå‘å¸ƒäº‹ä»¶åˆ°Topic
        
        Args:
            topic: ä¸»é¢˜åç§°
            event_data: äº‹ä»¶æ•°æ®ï¼ˆå­—å…¸æ ¼å¼ï¼‰
        """
        await self.create_producer()
        await self.producer.send_and_wait(topic, event_data)
        print(f"ğŸ“¢ å‘å¸ƒäº‹ä»¶åˆ°Topic [{topic}]: {event_data}")
    
    async def subscribe_events(self, topic: str, group_id: str, subscriber_name: str, callback):
        """
        ğŸ“¥ è®¢é˜…è€…ï¼šè®¢é˜…Topicäº‹ä»¶ï¼ˆä¸åŒçš„Consumer Groupï¼‰
        
        Args:
            topic: ä¸»é¢˜åç§°
            group_id: æ¶ˆè´¹è€…ç»„IDï¼ˆä¸åŒç»„éƒ½ä¼šæ”¶åˆ°æ¶ˆæ¯ï¼‰
            subscriber_name: è®¢é˜…è€…åç§°
            callback: å¤„ç†äº‹ä»¶çš„å›è°ƒå‡½æ•°
        """
        consumer = AIOKafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            group_id=group_id,  # ä¸åŒçš„group_idï¼Œæ¯ä¸ªç»„éƒ½ä¼šæ”¶åˆ°æ‰€æœ‰æ¶ˆæ¯
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            auto_offset_reset='earliest',
            enable_auto_commit=True
        )
        
        await consumer.start()
        self.consumers.append(consumer)
        print(f"ğŸ‘‚ [{subscriber_name}] è®¢é˜…Topic: {topic} (Group: {group_id})")
        
        try:
            async for message in consumer:
                event_data = message.value
                print(f"ğŸ“¬ [{subscriber_name}] æ”¶åˆ°äº‹ä»¶: {event_data}")
                await callback(event_data, subscriber_name)
        finally:
            await consumer.stop()
    
    async def close(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        if self.producer:
            await self.producer.stop()
        for consumer in self.consumers:
            await consumer.stop()
        print("ğŸ”Œ Kafka è¿æ¥å·²å…³é—­")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”æµ‹è¯•ä»£ç â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
async def test_kafka_multiple_groups():
    """æµ‹è¯• Kafka å¤šä¸ª Consumer Group å‘å¸ƒ-è®¢é˜…æ¨¡å¼"""
    
    kafka = KafkaMultipleGroups(
        bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS
    )
    
    topic_name = "user_register_events"
    
    # ğŸ¯ åœºæ™¯ï¼šç”¨æˆ·æ³¨å†Œäº‹ä»¶ï¼Œå¤šä¸ªæœåŠ¡éƒ½è¦æ¥æ”¶å¹¶å¤„ç†
    print("\n" + "="*50)
    print("ğŸ“Š Kafka å¤šä¸ª Consumer Group æ¨¡å¼ - å‘å¸ƒè®¢é˜…æ¨¡å¼æµ‹è¯•")
    print("="*50 + "\n")
    
    # æ¶ˆæ¯å¤„ç†å‡½æ•°
    async def process_email_service(event_data: dict, subscriber_name: str):
        """é‚®ä»¶æœåŠ¡å¤„ç†"""
        print(f"ğŸ“§ [{subscriber_name}] å‘é€æ¬¢è¿é‚®ä»¶...")
        await asyncio.sleep(0.5)
        print(f"âœ… [{subscriber_name}] æ¬¢è¿é‚®ä»¶å·²å‘é€: {event_data['email']}")
    
    async def process_coupon_service(event_data: dict, subscriber_name: str):
        """ä¼˜æƒ åˆ¸æœåŠ¡å¤„ç†"""
        print(f"ğŸŸï¸ [{subscriber_name}] å‘æ”¾æ–°äººä¼˜æƒ åˆ¸...")
        await asyncio.sleep(0.5)
        print(f"âœ… [{subscriber_name}] ä¼˜æƒ åˆ¸å·²å‘æ”¾: {event_data['user_id']}")
    
    async def process_analytics_service(event_data: dict, subscriber_name: str):
        """æ•°æ®åˆ†ææœåŠ¡å¤„ç†"""
        print(f"ğŸ“Š [{subscriber_name}] è®°å½•ç”¨æˆ·è¡Œä¸º...")
        await asyncio.sleep(0.5)
        print(f"âœ… [{subscriber_name}] æ•°æ®å·²è®°å½•: {event_data['user_id']}")
    
    # å¯åŠ¨3ä¸ªè®¢é˜…è€…ï¼ˆä¸åŒçš„Consumer Groupï¼‰
    print("ã€è®¢é˜…è€…ã€‘å¯åŠ¨ä¸­...\n")
    subscriber_task1 = asyncio.create_task(
        kafka.subscribe_events(topic_name, "email_service_group", "é‚®ä»¶æœåŠ¡", process_email_service)
    )
    subscriber_task2 = asyncio.create_task(
        kafka.subscribe_events(topic_name, "coupon_service_group", "ä¼˜æƒ åˆ¸æœåŠ¡", process_coupon_service)
    )
    subscriber_task3 = asyncio.create_task(
        kafka.subscribe_events(topic_name, "analytics_service_group", "æ•°æ®åˆ†ææœåŠ¡", process_analytics_service)
    )
    
    # ç­‰å¾…è®¢é˜…è€…å‡†å¤‡å¥½
    await asyncio.sleep(2)
    
    # å‘å¸ƒè€…ï¼šå‘å¸ƒ3ä¸ªç”¨æˆ·æ³¨å†Œäº‹ä»¶
    print("\nã€å‘å¸ƒè€…ã€‘å¼€å§‹å‘å¸ƒäº‹ä»¶...\n")
    for i in range(1, 4):
        await kafka.publish_event(topic_name, {
            "event_id": f"EVENT_{i:03d}",
            "user_id": f"USER_{i:06d}",
            "username": f"user{i}",
            "email": f"user{i}@example.com",
            "register_time": "2025-10-30 10:00:00",
            "source": "mobile_app"
        })
        await asyncio.sleep(1)
    
    # ç­‰å¾…äº‹ä»¶å¤„ç†å®Œæˆ
    await asyncio.sleep(5)
    
    # å–æ¶ˆè®¢é˜…è€…ä»»åŠ¡
    subscriber_task1.cancel()
    subscriber_task2.cancel()
    subscriber_task3.cancel()
    
    await asyncio.gather(subscriber_task1, subscriber_task2, subscriber_task3, return_exceptions=True)
    await kafka.close()
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(test_kafka_multiple_groups())


"""
ğŸ’¡ è¿è¡Œç»“æœè¯´æ˜ï¼š
- æ¯æ¡æ¶ˆæ¯ä¼šè¢«æ‰€æœ‰3ä¸ªConsumer Groupæ¥æ”¶ï¼ˆå¹¿æ’­ï¼‰
- æ¯ä¸ªæœåŠ¡éƒ½æœ‰ç‹¬ç«‹çš„Consumer Group
- æ¶ˆæ¯æŒä¹…åŒ–ï¼Œæ”¯æŒé‡å¤æ¶ˆè´¹
- é€‚åˆï¼šç”¨æˆ·è¡Œä¸ºè¿½è¸ªã€å¤šæœåŠ¡ååŒã€æ•°æ®åŒæ­¥ç­‰å¤§æ•°æ®å¹¿æ’­åœºæ™¯

ğŸ“¦ å®‰è£…ä¾èµ–ï¼š
pip install aiokafka

ğŸ’¡ æ ¸å¿ƒåŒºåˆ«ï¼š
- Consumer Groupæ¨¡å¼ï¼šåŒä¸€ç»„å†…è´Ÿè½½å‡è¡¡ï¼Œä¸€æ¡æ¶ˆæ¯åªè¢«ä¸€ä¸ªæ¶ˆè´¹è€…å¤„ç†
- å¤šConsumer Groupæ¨¡å¼ï¼šä¸åŒç»„éƒ½æ¥æ”¶ï¼Œå®ç°å‘å¸ƒ-è®¢é˜…
"""