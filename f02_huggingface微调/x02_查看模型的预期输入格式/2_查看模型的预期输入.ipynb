{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 查看语言模型的预期输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "你好<end_of_turn>\n",
      "<start_of_turn>model\n",
      "很高兴见到你<end_of_turn>\n",
      "<start_of_turn>user\n",
      "我叫美羊羊<end_of_turn>\n",
      "<start_of_turn>model\n",
      "你好美羊羊<end_of_turn>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_path = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                                          trust_remote_code=True, # tokenizer中包含自定义代码\n",
    "                                          )\n",
    "\n",
    "message = [\n",
    "    # {\"role\":\"system\",\"content\":\"you are a helpful assistant\"},\n",
    "    {\"role\":\"user\",\"content\":\"你好\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"很高兴见到你\"},\n",
    "    {\"role\":\"user\",\"content\":\"我叫美羊羊\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"你好美羊羊\"},\n",
    "]\n",
    "input = tokenizer.apply_chat_template(message,tokenize=False)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 查看音频模型的预期输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50258, 50260, 50359, 50363, 26410, 15914, 9175, 7248, 232, 7248, 232, 50257]\n",
      "<|startoftranscript|><|zh|><|transcribe|><|notimestamps|>你好我是美羊羊<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\",language = 'Chinese',task = \"transcribe\")\n",
    "\n",
    "a = '你好我是美羊羊'\n",
    "\n",
    "token = tokenizer(a).input_ids # token化\n",
    "print(token)\n",
    "\n",
    "input = tokenizer.decode(token,skip_special_tokens = False) # 输入格式\n",
    "print(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}{{ message.content }}{{ eos_token }}{% endfor %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.default_chat_template) # 查看特殊token处理逻辑逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
