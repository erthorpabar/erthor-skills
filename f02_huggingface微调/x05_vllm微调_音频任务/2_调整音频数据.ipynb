{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集与处理数据集\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import Audio\n",
    "import librosa\n",
    "\n",
    "# 加载模型\n",
    "from transformers import WhisperProcessor\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env_config\\py\\lib\\site-packages\\datasets\\load.py:1491: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'sentence'],\n",
       "    num_rows: 654\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据集\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")\n",
    "minds = minds.select_columns([ \"path\",\"audio\",\"english_transcription\" ])\n",
    "minds = minds.rename_columns({'english_transcription': 'sentence'})\n",
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 获取模型默认采样率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Processor = tokenizer特征标记器 + feature_extractor特征放大器\n",
    "\n",
    "使用方法\n",
    "feature_extractor(x['audio']['array'],sampling_rate=x['audio'][\"sampling_rate\"]).input_features[0]\n",
    "输入array，返回方差放大的，并且均值还是接近0的数据。这样让特征更加明显。\n",
    "返回input_features列\n",
    "\n",
    "使用方法\n",
    "tokenizer(x[\"sentence\"]).input_ids\n",
    "输入sentence文本语言，返回token。\n",
    "返回input_ids列 和 attention_mask列\n",
    "'''\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"chinese\", task=\"transcribe\")\n",
    "sampling_rate = processor.feature_extractor.sampling_rate\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 重置采样率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'C:\\\\Users\\\\Administrator\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\8b4d16f0fa6beceee204044b91fb9cfb987264e8f3b8f96a68f8f80c83c8ea3d\\\\en-AU~PAY_BILL\\\\response_4.wav',\n",
       " 'audio': {'path': 'C:\\\\Users\\\\Administrator\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\8b4d16f0fa6beceee204044b91fb9cfb987264e8f3b8f96a68f8f80c83c8ea3d\\\\en-AU~PAY_BILL\\\\response_4.wav',\n",
       "  'array': array([2.36120541e-05, 1.92325111e-04, 2.19284673e-04, ...,\n",
       "         9.40908678e-04, 1.16613181e-03, 7.20883720e-04]),\n",
       "  'sampling_rate': 16000},\n",
       " 'sentence': 'I would like to pay my electricity bill using my card can you please assist'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "minds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 feature特征放大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'sentence', 'input_features'],\n",
       "    num_rows: 654\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.map(\n",
    "    lambda x : # for i in dataset , x=dataset[i]\n",
    "    processor.feature_extractor(raw_speech=x['audio'][\"array\"],sampling_rate=x['audio'][\"sampling_rate\"],),\n",
    "    num_proc=1\n",
    ")\n",
    "minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调整前Mean: 9.19e-06, 调整前Variance: 0.0133\n",
      "调整后Mean: -0.491, 调整后Variance: 0.131\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 平均值，与方差\n",
    "sample = minds[0]\n",
    "print(f\"调整前Mean: {np.mean(sample['audio']['array']):.3}, 调整前Variance: {np.var(sample['audio']['array']):.3}\")\n",
    "print(f\"调整后Mean: {np.mean(sample['input_features']):.3}, 调整后Variance: {np.var(sample['input_features']):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 tokenizer文本标签化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'sentence', 'input_features', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 654\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.map(\n",
    "    lambda x : # for i in dataset , x=dataset[i]\n",
    "    processor.tokenizer(text=x[\"sentence\"],),\n",
    "    num_proc=1\n",
    ")\n",
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 processor同时把feature和tokenizer的事情做了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'sentence', 'input_features', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 654\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.map(\n",
    "    lambda x : # for i in dataset , x=dataset[i]\n",
    "    processor(audio=x['audio'][\"array\"],sampling_rate=x['audio'][\"sampling_rate\"],text=x[\"sentence\"],),\n",
    "    num_proc=1\n",
    ")\n",
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 feature的同时筛选时长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2500c158ea914f6fa1a40567328f9fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/654 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'sentence', 'input_features', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 654\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.map(\n",
    "    lambda x: \n",
    "    processor.feature_extractor(\n",
    "        [i[\"array\"] for i in x[\"audio\"]], # 要处理的数据，\n",
    "        sampling_rate=processor.feature_extractor.sampling_rate,\n",
    "        max_length=int(processor.feature_extractor.sampling_rate * 30), # 最长为30s音频\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "    ),\n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    num_proc=1, # 进程数量\n",
    ")\n",
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 使用path列数据-留下少于20s的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37abbd3102f147229070b14edfa92750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/654 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'sentence', 'input_features', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 624\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Audio_length = [librosa.get_duration(path=x) for x in minds[\"path\"]] # 获取每个样本时长 list格式\n",
    "minds = minds.add_column(\"Audio_length\", Audio_length)\n",
    "minds = minds.filter(\n",
    "    lambda x:\n",
    "    x < 20.0,\n",
    "    input_columns=[\"Audio_length\"]\n",
    ")\n",
    "minds = minds.remove_columns([\"Audio_length\"])\n",
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 使用audio列数据-留下少于10s的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d2d59159fd4beb8cf567e185569c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7425644295b7477f946630b7f26621ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'sentence', 'input_features', 'input_ids', 'attention_mask', 'labels', 'time'],\n",
       "    num_rows: 479\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算时长\n",
    "minds = minds.map(\n",
    "    lambda x : # for i in dataset , x=dataset[i]\n",
    "    {\"time\" : len(x['audio'][\"array\"]) / x['audio'][\"sampling_rate\"]},\n",
    "    num_proc=1\n",
    ")\n",
    "\n",
    "# 筛选\n",
    "minds = minds.filter(\n",
    "    lambda x: \n",
    "    x[\"time\"] < 10.0, \n",
    "    num_proc=1\n",
    ")\n",
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 使用gradio随机听取声音样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env_config\\py\\lib\\site-packages\\gradio\\processing_utils.py:583: UserWarning: Trying to convert audio automatically from float64 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as demo: # 界面\n",
    "    with gr.Column(): # 列布局\n",
    "        dataset = minds # 指定数据集\n",
    "        example = dataset.shuffle() # 打乱顺序\n",
    "        for i in range(4):\n",
    "            audio = (example[i][\"audio\"][\"sampling_rate\"],example[i][\"audio\"][\"array\"]) # (音频采样率，音频数据) ,  采样前4个\n",
    "            # label = dataset.features[\"intent_class\"].int2str(example[i][\"intent_class\"]) # 输入类别序号查看内容分类标签(类别序号)\n",
    "            output = gr.Audio(audio, \n",
    "                            # label=label\n",
    "                              )\n",
    "            \n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 查看有标签的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env_config\\py\\lib\\site-packages\\datasets\\load.py:1491: FutureWarning: The repository for marsyas/gtzan contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/marsyas/gtzan\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gtzan = load_dataset(\"marsyas/gtzan\", \"all\") # 1000个30s歌曲片段，分10个类别的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blues',\n",
       " 'classical',\n",
       " 'country',\n",
       " 'disco',\n",
       " 'hiphop',\n",
       " 'jazz',\n",
       " 'metal',\n",
       " 'pop',\n",
       " 'reggae',\n",
       " 'rock']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入int数字查看对应标签\n",
    "gtzan[\"train\"].features[\"genre\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rock'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = gtzan[\"train\"].features[\"genre\"].names\n",
    "a[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
