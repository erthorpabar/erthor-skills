{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 å¯¼å…¥åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®å’Œæ•°æ®å¤„ç†\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import Audio\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "from transformers import AutoModelForAudioClassification\n",
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "# è®­ç»ƒ\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# è¯„ä¼°æŒ‡æ ‡\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# è®¡ç®—èµ„æº\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "\n",
    "\n",
    "model_id = \"ntu-spml/distilhubert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 åŠ è½½æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env_config\\py\\lib\\site-packages\\datasets\\load.py:1491: FutureWarning: The repository for marsyas/gtzan contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/marsyas/gtzan\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'label'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file', 'audio', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan = load_dataset(\"marsyas/gtzan\", \"all\") # 1000ä¸ª30sæ­Œæ›²ç‰‡æ®µï¼Œåˆ†10ä¸ªç±»åˆ«çš„æ•°æ®é›†\n",
    "gtzan = gtzan[\"train\"].train_test_split(train_size=0.9,test_size=0.1,seed=42, shuffle=True, ) # åˆ‡åˆ†æ•°æ®é›†\n",
    "\n",
    "# è°ƒæ•´é‡‡æ ·ç‡\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id, do_normalize=True, return_attention_mask=True\n",
    ")\n",
    "sampling_rate = feature_extractor.sampling_rate\n",
    "gtzan = gtzan.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
    "\n",
    "gtzan = gtzan.rename_column(\"genre\", \"label\") # é‡å‘½å\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 åŠ è½½æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blues',\n",
       " 'classical',\n",
       " 'country',\n",
       " 'disco',\n",
       " 'hiphop',\n",
       " 'jazz',\n",
       " 'metal',\n",
       " 'pop',\n",
       " 'reggae',\n",
       " 'rock']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ„å»ºæ ‡ç­¾ï¼Œåºå·å¯¹åº”æ­£åå¯¹åº”å­—å…¸\n",
    "a = gtzan[\"train\"].features[\"label\"].names # æ ‡ç­¾åˆ—è¡¨\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'blues',\n",
       " '1': 'classical',\n",
       " '2': 'country',\n",
       " '3': 'disco',\n",
       " '4': 'hiphop',\n",
       " '5': 'jazz',\n",
       " '6': 'metal',\n",
       " '7': 'pop',\n",
       " '8': 'reggae',\n",
       " '9': 'rock'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_label_dict = {str(i):a[i]\n",
    "                 for i in range(len(a))\n",
    "                 }\n",
    "id_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blues': '0',\n",
       " 'classical': '1',\n",
       " 'country': '2',\n",
       " 'disco': '3',\n",
       " 'hiphop': '4',\n",
       " 'jazz': '5',\n",
       " 'metal': '6',\n",
       " 'pop': '7',\n",
       " 'reggae': '8',\n",
       " 'rock': '9'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_id_dict ={a[i]:str(i)\n",
    "                for i in range(len(a))\n",
    "                }\n",
    "label_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at ntu-spml/distilhubert and are newly initialized: ['classifier.bias', 'classifier.weight', 'encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id, do_normalize=True, return_attention_mask=True\n",
    ")\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(a),\n",
    "    label2id=label_id_dict,\n",
    "    id2label=id_label_dict,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 é¢„å¤„ç†-feature+ç•™ä¸‹å°äº30sçš„æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_values', 'attention_mask'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_values', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan = gtzan.map(\n",
    "    lambda x: \n",
    "    feature_extractor(\n",
    "        [i[\"array\"] for i in x[\"audio\"]], # è¦å¤„ç†çš„æ•°æ®ï¼Œ\n",
    "        sampling_rate=feature_extractor.sampling_rate,\n",
    "        max_length=int(feature_extractor.sampling_rate * 30), # æœ€é•¿ä¸º30séŸ³é¢‘\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "    ),\n",
    "    remove_columns=[\"audio\", \"file\"],\n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    num_proc=1, # è¿›ç¨‹æ•°é‡\n",
    ")\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gtzan['train'][0]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 å®šä¹‰è¯„ä¼°æŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 æ•°æ®é¢„å¤„ç†å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨æ•°æ®ä¼ è¿›æ¨¡å‹ä¹‹å‰å†åšä¸€éæ•°æ®å¤„ç†\n",
    "# å› ä¸ºå®é™…è¿è¡Œä¸­ä¼šå› ä¸ºæ•°æ®ç±»å‹é”™è¯¯è€ŒæŠ¥é”™ï¼Œæ‰€ä»¥åŠ äº†è¿™ä¸€å±‚é¢„å¤„ç†\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "\n",
    "class DataCollatorWithLabelConversion(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        batch = super().__call__(features)\n",
    "        if \"labels\" in batch:\n",
    "            batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.long)  # è½¬æ¢ä¸º LongTensor\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorWithLabelConversion(tokenizer=feature_extractor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 è®­ç»ƒå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env_config\\py\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    train_dataset=gtzan[\"train\"],\n",
    "    eval_dataset=gtzan[\"test\"],\n",
    "\n",
    "    tokenizer=feature_extractor,\n",
    "\n",
    "    compute_metrics=compute_metrics, # è®­ç»ƒåè¯„ä¼°\n",
    "\n",
    "    data_collator=data_collator,\n",
    "\n",
    "    args=TrainingArguments(\n",
    "        # â€”â€”â€”â€”â€”â€”æ¨¡å‹ä¿å­˜â€”â€”â€”â€”â€”â€”\n",
    "        output_dir=\"fted-gtzan\",  # æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "        save_strategy=\"epoch\",\n",
    "\n",
    "        # â€”â€”â€”â€”â€”â€”è®¡ç®—é‡â€”â€”â€”â€”â€”â€”\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=10,\n",
    "\n",
    "        # â€”â€”â€”â€”â€”â€”è®­ç»ƒç²¾åº¦â€”â€”â€”â€”â€”â€”\n",
    "        fp16=not torch.cuda.is_bf16_supported(),\n",
    "        bf16=torch.cuda.is_bf16_supported(),\n",
    "\n",
    "        # â€”â€”â€”â€”â€”â€”æ›´æ–°å‚æ•°â€”â€”â€”â€”â€”â€”\n",
    "        learning_rate=5e-5,\n",
    "        warmup_ratio=0.1,\n",
    "\n",
    "        # â€”â€”â€”â€”â€”â€”éªŒè¯å‚æ•°â€”â€”â€”â€”â€”â€”\n",
    "        evaluation_strategy=\"epoch\", # æŒ‰ç…§å‘¨æœŸè¯„ä¼°\n",
    "        per_device_eval_batch_size=4,\n",
    "\n",
    "        # â€”â€”â€”â€”â€”â€”logå‚æ•°â€”â€”â€”â€”â€”â€”\n",
    "        logging_steps=5,\n",
    "\n",
    "        # â€”â€”â€”â€”â€”â€”è®­ç»ƒåè¯„ä¼°â€”â€”â€”â€”â€”â€”\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bdf5bd39ae470596e77a2e0850e8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3680\\1108811776.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.long)  # è½¬æ¢ä¸º LongTensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1668, 'grad_norm': 2.1779890060424805, 'learning_rate': 2.2321428571428573e-06, 'epoch': 0.04}\n",
      "{'loss': 0.3099, 'grad_norm': 5.167806625366211, 'learning_rate': 4.464285714285715e-06, 'epoch': 0.09}\n",
      "{'loss': 0.2577, 'grad_norm': 5.803153991699219, 'learning_rate': 6.696428571428572e-06, 'epoch': 0.13}\n",
      "{'loss': 0.276, 'grad_norm': 11.999265670776367, 'learning_rate': 8.92857142857143e-06, 'epoch': 0.18}\n",
      "{'loss': 0.2078, 'grad_norm': 8.021317481994629, 'learning_rate': 1.1160714285714287e-05, 'epoch': 0.22}\n",
      "{'loss': 0.4447, 'grad_norm': 14.069929122924805, 'learning_rate': 1.3392857142857144e-05, 'epoch': 0.27}\n",
      "{'loss': 0.2241, 'grad_norm': 1.6829771995544434, 'learning_rate': 1.5625e-05, 'epoch': 0.31}\n",
      "{'loss': 0.2214, 'grad_norm': 7.3764238357543945, 'learning_rate': 1.785714285714286e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3646, 'grad_norm': 7.204859256744385, 'learning_rate': 2.0089285714285717e-05, 'epoch': 0.4}\n",
      "{'loss': 0.2672, 'grad_norm': 14.202727317810059, 'learning_rate': 2.2321428571428575e-05, 'epoch': 0.44}\n",
      "{'loss': 0.275, 'grad_norm': 22.416553497314453, 'learning_rate': 2.455357142857143e-05, 'epoch': 0.49}\n",
      "{'loss': 0.4045, 'grad_norm': 6.572040557861328, 'learning_rate': 2.6785714285714288e-05, 'epoch': 0.53}\n",
      "{'loss': 0.1619, 'grad_norm': 8.320562362670898, 'learning_rate': 2.9017857142857146e-05, 'epoch': 0.58}\n",
      "{'loss': 0.175, 'grad_norm': 3.366725444793701, 'learning_rate': 3.125e-05, 'epoch': 0.62}\n",
      "{'loss': 0.2712, 'grad_norm': 7.688167572021484, 'learning_rate': 3.348214285714286e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3334, 'grad_norm': 14.432865142822266, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.71}\n",
      "{'loss': 0.1778, 'grad_norm': 5.705700397491455, 'learning_rate': 3.794642857142857e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1496, 'grad_norm': 4.546976089477539, 'learning_rate': 4.017857142857143e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4216, 'grad_norm': 8.04909610748291, 'learning_rate': 4.2410714285714285e-05, 'epoch': 0.84}\n",
      "{'loss': 0.3214, 'grad_norm': 4.9944562911987305, 'learning_rate': 4.464285714285715e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3998, 'grad_norm': 8.546945571899414, 'learning_rate': 4.6875e-05, 'epoch': 0.93}\n",
      "{'loss': 0.2584, 'grad_norm': 37.530025482177734, 'learning_rate': 4.910714285714286e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83be29c1b184a81988d20bf0b0936ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6210741996765137, 'eval_accuracy': 0.79, 'eval_runtime': 20.5157, 'eval_samples_per_second': 4.874, 'eval_steps_per_second': 1.219, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3680\\1108811776.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.long)  # è½¬æ¢ä¸º LongTensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.191, 'grad_norm': 15.338900566101074, 'learning_rate': 4.985119047619048e-05, 'epoch': 1.02}\n",
      "{'loss': 0.188, 'grad_norm': 12.464792251586914, 'learning_rate': 4.960317460317461e-05, 'epoch': 1.07}\n",
      "{'loss': 0.2327, 'grad_norm': 2.070829391479492, 'learning_rate': 4.9355158730158735e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3073, 'grad_norm': 3.0361390113830566, 'learning_rate': 4.910714285714286e-05, 'epoch': 1.16}\n",
      "{'loss': 0.1921, 'grad_norm': 17.284364700317383, 'learning_rate': 4.8859126984126984e-05, 'epoch': 1.2}\n",
      "{'loss': 0.225, 'grad_norm': 4.638940811157227, 'learning_rate': 4.8611111111111115e-05, 'epoch': 1.24}\n",
      "{'loss': 0.1587, 'grad_norm': 6.803634166717529, 'learning_rate': 4.836309523809524e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3027, 'grad_norm': 6.493319988250732, 'learning_rate': 4.811507936507937e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1483, 'grad_norm': 2.6363468170166016, 'learning_rate': 4.7867063492063496e-05, 'epoch': 1.38}\n",
      "{'loss': 0.2126, 'grad_norm': 9.201255798339844, 'learning_rate': 4.761904761904762e-05, 'epoch': 1.42}\n",
      "{'loss': 0.1325, 'grad_norm': 8.509687423706055, 'learning_rate': 4.7371031746031745e-05, 'epoch': 1.47}\n",
      "{'loss': 0.2449, 'grad_norm': 12.818750381469727, 'learning_rate': 4.7123015873015876e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3738, 'grad_norm': 14.726103782653809, 'learning_rate': 4.6875e-05, 'epoch': 1.56}\n",
      "{'loss': 0.1147, 'grad_norm': 3.2866768836975098, 'learning_rate': 4.662698412698413e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2183, 'grad_norm': 6.771827697753906, 'learning_rate': 4.637896825396826e-05, 'epoch': 1.64}\n",
      "{'loss': 0.1348, 'grad_norm': 1.5544286966323853, 'learning_rate': 4.613095238095239e-05, 'epoch': 1.69}\n",
      "{'loss': 0.2242, 'grad_norm': 7.379948139190674, 'learning_rate': 4.5882936507936506e-05, 'epoch': 1.73}\n",
      "{'loss': 0.1788, 'grad_norm': 15.290183067321777, 'learning_rate': 4.563492063492064e-05, 'epoch': 1.78}\n",
      "{'loss': 0.1531, 'grad_norm': 7.312933444976807, 'learning_rate': 4.538690476190476e-05, 'epoch': 1.82}\n",
      "{'loss': 0.2992, 'grad_norm': 2.572110414505005, 'learning_rate': 4.5138888888888894e-05, 'epoch': 1.87}\n",
      "{'loss': 0.2322, 'grad_norm': 11.37501049041748, 'learning_rate': 4.489087301587302e-05, 'epoch': 1.91}\n",
      "{'loss': 0.2047, 'grad_norm': 9.365009307861328, 'learning_rate': 4.464285714285715e-05, 'epoch': 1.96}\n",
      "{'loss': 0.2652, 'grad_norm': 33.200626373291016, 'learning_rate': 4.439484126984127e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4314494fd44afcb235866c340faff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968475580215454, 'eval_accuracy': 0.8, 'eval_runtime': 20.4855, 'eval_samples_per_second': 4.882, 'eval_steps_per_second': 1.22, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3680\\1108811776.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.long)  # è½¬æ¢ä¸º LongTensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1729, 'grad_norm': 1.4056661128997803, 'learning_rate': 4.41468253968254e-05, 'epoch': 2.04}\n",
      "{'loss': 0.1627, 'grad_norm': 7.254873275756836, 'learning_rate': 4.3898809523809523e-05, 'epoch': 2.09}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31måœ¨å½“å‰å•å…ƒæ ¼æˆ–ä¸Šä¸€ä¸ªå•å…ƒæ ¼ä¸­æ‰§è¡Œä»£ç æ—¶ Kernel å´©æºƒã€‚\n",
      "\u001b[1;31mè¯·æŸ¥çœ‹å•å…ƒæ ¼ä¸­çš„ä»£ç ï¼Œä»¥ç¡®å®šæ•…éšœçš„å¯èƒ½åŸå› ã€‚\n",
      "\u001b[1;31må•å‡»<a href='https://aka.ms/vscodeJupyterKernelCrash'>æ­¤å¤„</a>äº†è§£è¯¦ç»†ä¿¡æ¯ã€‚\n",
      "\u001b[1;31mæœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ Jupyter <a href='command:jupyter.viewOutput'>log</a>ã€‚"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
