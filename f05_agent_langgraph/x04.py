'''åæ€å’Œæ¨ç† '''


# å°†å½“å‰ç›®å½•åŠ å…¥æœç´¢è·¯å¾„
import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# å¯¼å…¥åŒ…
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END, MessagesState
from langchain_openai import ChatOpenAI

# è®°å¿†
from langgraph.checkpoint.memory import MemorySaver

# å·¥å…·
from langchain_core.tools import tool
from langgraph.prebuilt import ToolNode

# åæ€
from langchain_community.tools.tavily_search import TavilySearchResults

# å¯¼å…¥ç¯å¢ƒå˜é‡
api_url = os.getenv("LLM_URL")
api_key = os.getenv("LLM_API_KEY")
model = os.getenv("LLM_MODEL")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”å…¬å…±å˜é‡â€”â€”â€”â€”â€”â€”â€”â€”â€”
llm = ChatOpenAI(model=model, api_key=api_key, base_url=api_url)  


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”å®šä¹‰å‡½æ•°â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# ===tool å‡½æ•°
# 1 å·¥å…·å‡½æ•°
from langchain_community.tools import DuckDuckGoSearchResults
search = DuckDuckGoSearchResults(max_results=2)

# 2 åˆ¤æ–­æ˜¯å¦è°ƒç”¨å·¥å…·
def should_continue(state: MessagesState):
    last_message = state["messages"][-1] # è·å–æœ€åä¸€æ¡ä¿¡æ¯
    # 1 æ£€æŸ¥æ˜¯å¦æœ‰tool_callså±æ€§ 2 æ£€æŸ¥å·¥å…·åˆ—è¡¨å­˜åœ¨å·¥å…·
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        
        # æ‰“å°å·¥å…·è°ƒç”¨ä¿¡æ¯
        tool_names = [tc["name"] for tc in last_message.tool_calls]
        print(f"ğŸ”§ æ­£åœ¨è°ƒç”¨å·¥å…·: {', '.join(tool_names)}")

        return "tools"
    
    print("ğŸ”§ ä¸éœ€è¦è°ƒç”¨å·¥å…·")
    return END # ç‰¹æ®Šå¸¸é‡ ä»£è¡¨æœ¬æ¬¡æ‰§è¡Œç»“æœç»“æŸ éœ€è¦ç”¨æˆ·å†æ¬¡è¾“å…¥å¼€å¯ä¸‹ä¸€è½®æ‰§è¡Œ

# 3 ç»‘å®šå·¥å…·
tools = [search]
llm_with_tools = llm.bind_tools(tools) 

# ===èŠå¤© å‡½æ•°
def agent(state: MessagesState):
    system_prompt = '''ä½ æ˜¯ä¸€ä¸ª ReAct (Reasoning + Acting) Agentã€‚
å¤„ç†ç”¨æˆ·é—®é¢˜æ—¶ï¼Œè¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š
1. Thought(æ€è€ƒ):åˆ†æé—®é¢˜éœ€è¦ä»€ä¹ˆä¿¡æ¯
2. Action(è¡ŒåŠ¨):å†³å®šè°ƒç”¨å“ªä¸ªå·¥å…·
3. Observation(è§‚å¯Ÿ):åˆ†æå·¥å…·è¿”å›çš„ç»“æœ
4. Answer(å›ç­”):åŸºäºè§‚å¯Ÿç»™å‡ºæœ€ç»ˆç­”æ¡ˆ

å§‹ç»ˆå±•ç¤ºä½ çš„æ¨ç†è¿‡ç¨‹ã€‚ '''
    messages = [{"role": "system", "content": system_prompt}] + state["messages"]
    return {"messages": [llm_with_tools.invoke(messages)]}

# â€”â€”â€”â€”â€”â€”â€”â€”â€”å®šä¹‰è¿è¡Œæµç¨‹â€”â€”â€”â€”â€”â€”â€”â€”â€”
# åˆ›å»ºå›¾
graph = StateGraph(MessagesState)

# æ³¨å†ŒèŠ‚ç‚¹
graph.add_node("agent", agent)
graph.add_node("tools", ToolNode(tools))

# å…¥å£è¾¹
graph.add_edge(START, "agent")

# ä¸­é—´è¾¹
graph.add_edge("tools", "agent")

# å‡ºå£è¾¹
graph.add_conditional_edges(
    "agent", # ä»è¿™ä¸ªèŠ‚ç‚¹å¼€å§‹
    should_continue,  # å†³å®šèµ°å‘
    {
        "tools": "tools", # å¦‚æœè¿”å› "tools"ï¼Œèµ°å‘ tools èŠ‚ç‚¹
        END: END # å¦‚æœè¿”å› "END"ï¼Œèµ°å‘ END èŠ‚ç‚¹
    }
)


# â€”â€”â€”â€”â€”â€”â€”â€”â€”è¿è¡Œâ€”â€”â€”â€”â€”â€”â€”â€”â€”
# ç¼–è¯‘å›¾
app = graph.compile()

# ä¸€æ¬¡æ€§æ‰§è¡Œ
user_input = '2024å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–è·å¾—è€…æ˜¯è°ï¼Ÿä»–ä»¬çš„ä¸»è¦è´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ'
res = app.invoke({"messages": [("user", user_input)]})
print("=" * 50 + " å¯¹è¯ç»“æœ " + "=" * 50)
print(res["messages"][-1].content)

# æ‰€æœ‰å†å²å¯¹è¯
print("=" * 50 + " å®Œæ•´å¯¹è¯å†å² " + "=" * 50)
for i, msg in enumerate(res["messages"],1):
    print(i,msg.type)
    print(msg)